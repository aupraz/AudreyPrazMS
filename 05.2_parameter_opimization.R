### STEP 1: Establish sources and libraries ####

# Loading Libraries #
library(abc)
library(data.table)
library(doParallel)
library(dplyr)
library(foreach)
library(parallel)
library(poems)
library(raster)
library(sf)
library(terra)
library(tidyr)
library(scales)
library(rnaturalearth)
library(enmSdmX) # updated version of enmSdm package
library(bayestestR)
library(fitdistrplus)

# Truncated distribution functions

## normal
rnormt <- function(n, range, mean, sd, ...) {
  F.a <- pnorm(min(range), mean = mean, sd = sd, ...)
  F.b <- pnorm(max(range), mean = mean, sd = sd, ...)
  u <- runif(n, min = F.a, max = F.b)
  qnorm(p = u, mean = mean, sd = sd, ...)
}

## log-normal
rlnormt <- function(n, range, meanlog, sdlog, ...) {
  F.a <- plnorm(min(range), meanlog = meanlog, sdlog = sdlog, ...)
  F.b <- plnorm(max(range), meanlog = meanlog, sdlog = sdlog, ...)
  u <- runif(n, min = F.a, max = F.b)
  qlnorm(u, meanlog = meanlog, sdlog = sdlog, ...)
}

## gamma
rgammat <- function(n, range, shape, rate, ...) {
  F.a <- pgamma(min(range), shape = shape, rate = rate,...)
  F.b <- pgamma(max(range), shape = shape, rate = rate, ...)
  u <- runif(n, min = F.a, max = F.b)
  qgamma(u, shape = shape,rate = rate, ...)
}

## beta
rbetat <- function(n, range, shape1, shape2, ...) {
  F.a <- pbeta(min(range), shape1, shape2,...)
  F.b <- pbeta(max(range), shape1, shape2,...)
  u <- runif(n, min = F.a, max = F.b)
  qbeta(u, shape1, shape2,...)
}

## triangular
rtrianglet <- function(n, range, min, max, ...) {
  F.a <- ptriang(min(range), min = min, max = max, ...)
  F.b <- ptriang(max(range), min = min, max = max, ...)
  u <- runif(n, min = F.a, max = F.b)
  qtriang(u, min = min, max = max, ...)
}

## poisson
rpoist <- function(n, range, lambda, ...) {
  F.a <- ppois(min(range), lambda, ...)
  F.b <- ppois(max(range), lambda, ...)
  u <- runif(n, min = F.a, max = F.b)
  qpois(p = u, lambda, ...)
}

## negbin
rnbt <- function(n, range, size, mu, ...) {
  F.a <- pnbinom(min(range), size = size, mu = mu, ...)
  F.b <- pnbinom(max(range), size = size, mu = mu, ...)
  u <- runif(n, min = F.a, max = F.b)
  qnbinom(u, size = size, mu = mu, ...)
}



# Establishing source files #
DATA_DIR <- "data"
OUTPUT_DIR <- "C:/Users/Sean Tomlinson/Desktop/out_sims"
SCRIPT_DIR <- "code"

# Load boutique ABC functions
source(file.path(SCRIPT_DIR,"custom_funcs.R"))
source(file.path(SCRIPT_DIR,"pp_check.R"))


round_any <- function(x, accuracy, f = round) {
  f(x/ accuracy) * accuracy
}


#### 'poems' parameters ####
SAMPLES <- 15000L # the number of samples generated by Latin Hypercube Sampling
PARALLEL_CORES <- min(c(parallel::detectCores()*0.5, SAMPLES))/2 # the number of cores defaulted to in parallel simulations
TIMESTEPS <- 271  # the number of time steps over which the simulations run (in years)
BURNINSTEPS <- 50
TIMESEQ <- seq(to = 2020, by = 1, length.out = (TIMESTEPS - BURNINSTEPS))
PLOTSEQ <- floor(seq(BURNINSTEPS + 1, TIMESTEPS, length.out = 6))



### Step 4: Resample and reiterate models ####
sample_data <- fread("third_try/ST_abc_v3/lhs_run_25000.csv")
selected_sims <- fread("third_try/ST_abc_v3/selected_sims_corrected.csv")
best_models <- readRDS("third_try/ST_abc_v3/abc_first_pass_corrected.RDS")


options(scipen = 999)

sample_params <- sample_data
selected_params <- selected_sims
abc_pass <- best_models

## Iterate through each demo variable and check distributions
param_dists <- lapply(colnames(selected_params)[3:12], function(param) {
  message(param)
  x <- selected_params[[param]]
  w <- selected_params[["Weights"]]/sum(selected_params[["Weights"]])
  min.max <- as.vector(quantile(x, c(0.05,0.95)))
  
  # https://stackoverflow.com/questions/32871602/r-generate-data-from-a-probability-density-distribution
  {
    density_x <- density(x, from = min.max[1], to = min.max[2],
                        bw = "SJ", kernel = "gaussian",
                        n = 1000, adjust = 0.25,
                        weights = w)
    resample_x <- approx(
      x = cumsum(density_x$y)/sum(density_x$y),
      y = density_x$x,
      n = 10000,
      yleft = min(density_x$x), yright = max(density_x$x),
      na.rm = TRUE)$y
  }
  par(mfrow = c(2, 1))
  {plot(density(x, from = min(x), to = max(x)), main = param)
    abline(v = min.max, col = "grey70", lty = 2, lwd = 2)}
  disc <- ifelse(param %in% c("rmax_quantile", "dispersal_p", "dispersal_b", "dispersal_n_k_threshold", "max_dens", "trans_n"), TRUE, FALSE)
  if (param %in% c("rmax_quantile", "dispersal_p", "dispersal_b", "dispersal_n_k_threshold", "max_dens", "trans_n")) {
    resample_x <- round(resample_x)
  }
  # Estimate parameters from interpolated/density estimated obs
  orig_dists <- list(
    normD <- tryCatch(fitdist(resample_x, distr = "norm", method = "mge",
                              gof = "KS", discrete = disc),
                      error = function(err) invisible({err})),
    lnD <- tryCatch(fitdist(resample_x, distr = "lnorm", method = "mge",
                            gof = "KS", discrete = disc),
                    error = function(err) invisible({err})),
    gD <- tryCatch(fitdist(resample_x, distr = "gamma", method = "mge",
                           gof = "KS", discrete = disc),
                   error = function(err) invisible({err})),
    bD <- tryCatch(fitdist(resample_x, distr = "beta", method = "mge",
                           gof = "KS", discrete = disc),
                   error = function(err) invisible({err})),
    triD <- tryCatch(fitdist(resample_x, distr = "triang", method = "mge",
                             gof = "KS", discrete = disc),
                     error = function(err) invisible({err})),
    unifD <- tryCatch(fitdist(resample_x, distr = "unif",method = "mge",
                              gof = "KS", discrete = disc),
                      error = function(err) invisible({err})),
    poisD <- tryCatch(fitdist(resample_x, distr = "pois", method = "mme",
                              discrete = TRUE),
                      error = function(err) invisible({err})),
    negbD <- tryCatch(fitdist(resample_x, distr = "nbinom", method = "mme",
                              discrete = TRUE),
                      error = function(err) invisible({err}))
  )
  # index for dist that errored
  keep_dists <- sapply(orig_dists, function(i) inherits(i, "error"))
  orig_dists <- orig_dists[!keep_dists]
  names(orig_dists) <- c("norm", "lnorm", "gamma", "beta",
                         "triangular",
                         "unif", "pois", "negbin")[!keep_dists]
  cdfcomp(orig_dists, main = param, addlegend = TRUE, ylim = c(0, 1))
  par(mfrow = c(1,1))
  
  return(
    list(
      Output = orig_dists)
  )
})
names(param_dists) <- colnames(selected_params)[3:12]

# For each param, calculate the min AIC, then calc. delta AIC for each distribution
delta_aic <- lapply(names(param_dists), function(param) {
  var_dist <- param_dists[param][param][[1]]$Output
  dist_aic <- sapply(var_dist, function(i) i$aic)
  delta_aic <- dist_aic - min(dist_aic[is.finite(dist_aic)])
  delta_aic <- sort(delta_aic, na.last = TRUE)
  return(delta_aic)})
names(delta_aic) <- names(param_dists)
delta_aic 

# Make 1,000 resamples based on results. Here each parameter is resampled depending on the truncated distribution functions
# that are identified as being the most appropriate. Hence, a number of the resampling functions can be included or excluded
# depending on the results specific to the resampling run.
SAMPLES <- 15000

dt_lhs_run2 <- data.table()

dt_lhs_run2$standard_deviation = rnormt(n = SAMPLES,
                                        range = as.numeric(quantile(as.numeric(selected_params[["standard_deviation"]]), probs = c(0.05,0.95))),
                                        mean = as.numeric(param_dists$standard_deviation$Output$norm$estimate[1]),
                                        sd = as.numeric(param_dists$standard_deviation$Output$norm$estimate[2]))

dt_lhs_run2$growth_rate_max = rlnormt(n = SAMPLES,
                                      range = as.numeric(quantile(as.numeric(selected_params[["growth_rate_max"]]), probs = c(0.05,0.95))),
                                      meanlog = as.numeric(param_dists$growth_rate_max$Output$lnorm$estimate[1]),
                                      sdlog = as.numeric(param_dists$growth_rate_max$Output$lnorm$estimate[2]))

dt_lhs_run2$density_max = rlnormt(n = SAMPLES,
                                  range = as.numeric(quantile(as.numeric(selected_params[["density_max"]]), probs = c(0.05,0.95))),
                                  meanlog = as.numeric(param_dists$density_max$Output$lnorm$estimate[1]),
                                  sdlog = as.numeric(param_dists$density_max$Output$lnorm$estimate[2]))

# look at max et min with this command summary(sample_data[["dispersal_p"]])
dt_lhs_run2$dispersal_p = runif(n = SAMPLES, min = 0.007, max = 0.596)
# # dispersal_p = gamma
# dt_lhs_run2$dispersal_p = rgammat(n = SAMPLES,
#                                   range = quantile(selected_params[["dispersal_p"]], probs = c(0.05,0.95)),
#                     shape = param_dists$dispersal_p$Output$gamma$estimate[1],
#                     rate = param_dists$dispersal_p$Output$gamma$estimate[2])

dt_lhs_run2$dispersal_b = rnormt(n = SAMPLES,
                                 range = as.numeric(quantile(as.numeric(selected_params[["dispersal_b"]]), probs = c(0.05,0.95))),
                                 mean = as.numeric(param_dists$dispersal_b$Output$norm$estimate[1]),
                                 sd = as.numeric(param_dists$dispersal_b$Output$norm$estimate[2]))

dt_lhs_run2$abundance_threshold = rnormt(n = SAMPLES,
                                        range = as.numeric(quantile(as.numeric(selected_params[["abundance_threshold"]]), probs = c(0.05,0.95))),
                                        mean = as.numeric(param_dists$abundance_threshold$Output$norm$estimate[1]),
                                        sd = as.numeric(param_dists$abundance_threshold$Output$norm$estimate[2]))
dt_lhs_run2$abundance_threshold = round(dt_lhs_run2$abundance_threshold, 0)
                                        

dt_lhs_run2$harvest_max = rbetat(n = SAMPLES,
                                 range = as.numeric(quantile(as.numeric(selected_params[["harvest_max"]]), probs = c(0.05,0.95))),
                                 shape1 = as.numeric(param_dists$harvest_max$Output$beta$estimate[1]),
                                 shape2 = as.numeric(param_dists$harvest_max$Output$beta$estimate[2]))

# # harvest_z = norm
 dt_lhs_run2$harvest_z = rlnormt(n = SAMPLES,
                                range = as.numeric(quantile(as.numeric(selected_params[["harvest_z"]]), probs = c(0.05,0.95))),
                                meanlog = as.numeric(param_dists$harvest_z$Output$lnorm$estimate[1]),
                                sdlog = as.numeric(param_dists$harvest_z$Output$lnorm$estimate[2]))
# harvest_z = gamma
dt_lhs_run2$harvest_z = rgammat(n = SAMPLES,
                                  range = quantile(selected_params[["harvest_z"]], probs = c(0.05,0.95)),
                                  shape = param_dists$harvest_z$Output$gamma$estimate[1],
                                  rate = param_dists$harvest_z$Output$gamma$estimate[2])

dt_lhs_run2$p = rbetat(n = SAMPLES,
                       range = as.numeric(quantile(as.numeric(selected_params[["p"]]), probs = c(0.05,0.95))),
                       shape1 = as.numeric(param_dists$p$Output$beta$estimate[1]),
                       shape2 = as.numeric(param_dists$p$Output$beta$estimate[2]))

dt_lhs_run2$cat_weight = rbetat(n = SAMPLES,
                                range = as.numeric(quantile(as.numeric(selected_params[["cat_weight"]]), probs = c(0.05,0.95))),
                                shape1 = as.numeric(param_dists$cat_weight$Output$beta$estimate[1]),
                                shape2 = as.numeric(param_dists$cat_weight$Output$beta$estimate[2]))




summary(dt_lhs_run2)
dt_lhs_run2



par(mfrow = n2mfrow(ncol(dt_lhs_run2)))
lapply(colnames(dt_lhs_run2), function(param) {
  orig <- as.numeric(selected_params[[param]])
  sampled <- dt_lhs_run2[[param]]
  dOrig <- density(orig, from = min(orig), to = max(orig))
  dSamp <- density(sampled, from = min(sampled), to = max(sampled))
  plot(dOrig, ylim = c(min(c(dOrig$y, dSamp$y)), max(c(dOrig$y, dSamp$y))),
       main = param,
       col = "black", lty = 1)
  #rug(orig, side = 1, col = "black")
  #rug(sampled, side = 3, col = "blue")
  lines(dSamp, col = "blue", lty = 2, lwd = 2)
  abline(v = quantile(orig, c(0.05,0.95)), lty = 3, col = "grey70", lwd = 2)
})

nsims<-15000

niche_lookup <- list.files("data/niche_cuts/proj_matrices/projected", ".RDS")
niche_lookup <- data.table(niche_ref = gsub(".RDS", "", niche_lookup))
niche_lookup <- as.data.table(niche_lookup)
niche_lookup[, Width := as.numeric(sapply(strsplit(niche_ref, "_"), head, 1))]
#niche_lookup[, Width := 1.0]
niche_lookup

set.seed(17559326)
dt_lhs_run2[, niche_ref := sample(niche_lookup$niche_ref, nsims, replace = TRUE)]

#dt_lhs_run2$niche_ref <- {set.seed(17559326); setDT(niche_lookup)[sample(.N, nsims, replace = TRUE), ][, -2]}
#dt_lhs_run2$niche_ref <- {setDT(niche_lookup)[sample(.N, nsims, replace = TRUE), ]}
#dt_lhs_run2$niche_ref <- substr(dt_lhs_run2$niche_ref,1,nchar(dt_lhs_run2$niche_ref)-4)

#round(prop.table(table(as.numeric(sapply(strsplit(split = "_", x = niche_lookup$niche_ref), "[", 1)))), 3)
#round(prop.table(table(as.numeric(sapply(strsplit(split = "_", x = dt_lhs_run2$niche_ref), "[", 1)))), 3)


{#set.seed(54612)
  dt_lhs_run2$UniqueID <- paste0(stringi::stri_rand_strings(nsims, 4, "[A-Z]"),
                                 stringi::stri_rand_strings(nsims, 4, "[0-9]"),
                                 "_", dt_lhs_run2$niche_ref)
}
any(duplicated(dt_lhs_run2$UniqueID))
head(dt_lhs_run2$UniqueID)
dt_lhs_run2 <- dt_lhs_run2[, c(12, 11, 1:10)]
head(dt_lhs_run2)
# Save new sample data
fwrite(dt_lhs_run2, "third_try/ST_abc_v3/lhs2_corrected.csv")



